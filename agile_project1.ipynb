{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mnz8oJAbKW_hEeffRV9nUtoFKbLvN2n3","timestamp":1696615141834}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aM61uEOfKvXc","executionInfo":{"status":"ok","timestamp":1696573197025,"user_tz":-330,"elapsed":29476,"user":{"displayName":"Vidhya Sanjana K","userId":"10741726791244027257"}},"outputId":"b7186001-eb3a-4d5f-fcda-6f8e648e50ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#DEEP LEARNING:"],"metadata":{"id":"_ERK7zvsMEoG"}},{"cell_type":"markdown","source":["CLASSIFICATION:"],"metadata":{"id":"aNOlTTt9MOEs"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(500, activation='relu', input_dim=13))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=100)\n","print(model.predict(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPB9rk3P7q5X","executionInfo":{"status":"ok","timestamp":1696614300946,"user_tz":-330,"elapsed":25691,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"c16ba94d-30d8-4c89-dfae-3cc4f5f8f1d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","24/24 [==============================] - 3s 10ms/step - loss: 1.8675 - accuracy: 0.5885\n","Epoch 2/100\n","24/24 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.6562\n","Epoch 3/100\n","24/24 [==============================] - 0s 7ms/step - loss: 0.6690 - accuracy: 0.6589\n","Epoch 4/100\n","24/24 [==============================] - 0s 10ms/step - loss: 0.5428 - accuracy: 0.7135\n","Epoch 5/100\n","24/24 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.6732\n","Epoch 6/100\n","24/24 [==============================] - 0s 7ms/step - loss: 0.5708 - accuracy: 0.7383\n","Epoch 7/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7513\n","Epoch 8/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7591\n","Epoch 9/100\n","24/24 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.7734\n","Epoch 10/100\n","24/24 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7357\n","Epoch 11/100\n","24/24 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7943\n","Epoch 12/100\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4373 - accuracy: 0.7812\n","Epoch 13/100\n","24/24 [==============================] - 0s 9ms/step - loss: 0.4272 - accuracy: 0.7917\n","Epoch 14/100\n","24/24 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.6966\n","Epoch 15/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7734\n","Epoch 16/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8424\n","Epoch 17/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7891\n","Epoch 18/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7656\n","Epoch 19/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8268\n","Epoch 20/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8438\n","Epoch 21/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8034\n","Epoch 22/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8021\n","Epoch 23/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7734\n","Epoch 24/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8125\n","Epoch 25/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8411\n","Epoch 26/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8516\n","Epoch 27/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8359\n","Epoch 28/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8307\n","Epoch 29/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8398\n","Epoch 30/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8490\n","Epoch 31/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8216\n","Epoch 32/100\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.8372\n","Epoch 33/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8438\n","Epoch 34/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8620\n","Epoch 35/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8034\n","Epoch 36/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8333\n","Epoch 37/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8685\n","Epoch 38/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8555\n","Epoch 39/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8242\n","Epoch 40/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8659\n","Epoch 41/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8594\n","Epoch 42/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8411\n","Epoch 43/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8529\n","Epoch 44/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8581\n","Epoch 45/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8099\n","Epoch 46/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8333\n","Epoch 47/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8099\n","Epoch 48/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8255\n","Epoch 49/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8477\n","Epoch 50/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8307\n","Epoch 51/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8685\n","Epoch 52/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8294\n","Epoch 53/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7240\n","Epoch 54/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8620\n","Epoch 55/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8359\n","Epoch 56/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8503\n","Epoch 57/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8398\n","Epoch 58/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8581\n","Epoch 59/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8607\n","Epoch 60/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8477\n","Epoch 61/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8711\n","Epoch 62/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8255\n","Epoch 63/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8346\n","Epoch 64/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8372\n","Epoch 65/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8698\n","Epoch 66/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8190\n","Epoch 67/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8451\n","Epoch 68/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8594\n","Epoch 69/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8411\n","Epoch 70/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8594\n","Epoch 71/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8672\n","Epoch 72/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8424\n","Epoch 73/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8555\n","Epoch 74/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8073\n","Epoch 75/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8385\n","Epoch 76/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8581\n","Epoch 77/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8555\n","Epoch 78/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8607\n","Epoch 79/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8659\n","Epoch 80/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8737\n","Epoch 81/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8529\n","Epoch 82/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8568\n","Epoch 83/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8789\n","Epoch 84/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8698\n","Epoch 85/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.8750\n","Epoch 86/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8398\n","Epoch 87/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8659\n","Epoch 88/100\n","24/24 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8672\n","Epoch 89/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8724\n","Epoch 90/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8203\n","Epoch 91/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7995\n","Epoch 92/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8646\n","Epoch 93/100\n","24/24 [==============================] - 0s 8ms/step - loss: 0.3253 - accuracy: 0.8646\n","Epoch 94/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8867\n","Epoch 95/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8698\n","Epoch 96/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.8594\n","Epoch 97/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8594\n","Epoch 98/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8802\n","Epoch 99/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8620\n","Epoch 100/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8581\n","9/9 [==============================] - 0s 3ms/step\n","[[9.8558575e-01]\n"," [9.9083382e-01]\n"," [4.1769274e-02]\n"," [9.6970111e-01]\n"," [9.3610942e-02]\n"," [8.5797513e-01]\n"," [1.7807992e-02]\n"," [2.8467663e-02]\n"," [9.0225869e-01]\n"," [7.5340481e-03]\n"," [9.7110015e-01]\n"," [4.7459383e-03]\n"," [9.2323714e-01]\n"," [9.9992222e-01]\n"," [7.6309539e-02]\n"," [9.6552676e-01]\n"," [2.2890737e-02]\n"," [9.9836504e-01]\n"," [9.7968137e-01]\n"," [2.8565297e-02]\n"," [8.2805312e-01]\n"," [1.5290035e-01]\n"," [6.1334455e-01]\n"," [4.7531556e-03]\n"," [8.2805312e-01]\n"," [9.7991520e-01]\n"," [9.6087193e-01]\n"," [5.8018667e-01]\n"," [7.4417591e-03]\n"," [9.3944842e-01]\n"," [7.4000823e-01]\n"," [6.2784791e-01]\n"," [7.9559582e-01]\n"," [9.9083382e-01]\n"," [9.4499677e-01]\n"," [9.3613863e-01]\n"," [8.2805312e-01]\n"," [6.2850302e-01]\n"," [9.5818633e-01]\n"," [9.7110975e-01]\n"," [2.8467663e-02]\n"," [5.8272976e-02]\n"," [8.8272065e-01]\n"," [6.1334455e-01]\n"," [1.6157890e-02]\n"," [6.2835366e-03]\n"," [8.0552183e-02]\n"," [6.3024610e-01]\n"," [8.0797559e-01]\n"," [7.7969050e-01]\n"," [5.3839827e-01]\n"," [1.0854099e-02]\n"," [8.8429821e-01]\n"," [5.5780946e-03]\n"," [9.6087193e-01]\n"," [9.5818633e-01]\n"," [3.6274382e-01]\n"," [1.1404734e-02]\n"," [9.0160167e-01]\n"," [9.7845542e-01]\n"," [8.3177739e-01]\n"," [1.4324869e-01]\n"," [7.4417554e-03]\n"," [7.7969062e-01]\n"," [1.1644156e-02]\n"," [5.3523090e-02]\n"," [9.9686599e-01]\n"," [6.4910787e-01]\n"," [6.2835366e-03]\n"," [9.9423206e-01]\n"," [8.0937058e-01]\n"," [7.4417591e-03]\n"," [5.5194145e-01]\n"," [9.5700139e-01]\n"," [9.0284777e-01]\n"," [8.0100989e-01]\n"," [1.7807992e-02]\n"," [9.1295761e-01]\n"," [7.4256063e-01]\n"," [9.3882453e-01]\n"," [2.9331040e-01]\n"," [7.3467292e-02]\n"," [3.7215460e-02]\n"," [2.8751953e-02]\n"," [9.5867354e-01]\n"," [8.8614319e-03]\n"," [9.7110015e-01]\n"," [2.0974416e-01]\n"," [2.9331040e-01]\n"," [9.3944842e-01]\n"," [7.9795635e-01]\n"," [2.8565297e-02]\n"," [9.8931772e-01]\n"," [9.6499813e-01]\n"," [9.2795575e-01]\n"," [8.7102580e-01]\n"," [6.4910787e-01]\n"," [5.0767224e-02]\n"," [1.0630125e-03]\n"," [6.6560499e-02]\n"," [9.8943669e-01]\n"," [6.5790817e-02]\n"," [8.9329350e-01]\n"," [9.2147154e-01]\n"," [5.7263736e-02]\n"," [9.5389825e-01]\n"," [1.1404734e-02]\n"," [9.4936126e-01]\n"," [4.6309936e-01]\n"," [9.7586036e-01]\n"," [9.0160167e-01]\n"," [9.7586036e-01]\n"," [9.9047303e-01]\n"," [1.2837045e-01]\n"," [9.4398212e-01]\n"," [9.8458499e-01]\n"," [8.7902498e-01]\n"," [9.3475020e-01]\n"," [9.6423107e-01]\n"," [4.9654865e-03]\n"," [7.8198785e-01]\n"," [8.7249988e-01]\n"," [7.1503678e-03]\n"," [2.0386647e-01]\n"," [1.5632997e-01]\n"," [4.7531556e-03]\n"," [9.3201321e-01]\n"," [9.2817539e-01]\n"," [8.0937058e-01]\n"," [9.0547121e-01]\n"," [6.2784797e-01]\n"," [1.0630125e-03]\n"," [9.9188966e-01]\n"," [9.8943669e-01]\n"," [2.0234920e-02]\n"," [9.9528307e-01]\n"," [2.6685910e-03]\n"," [8.7249988e-01]\n"," [9.9528307e-01]\n"," [8.7902498e-01]\n"," [8.1930506e-01]\n"," [9.2939359e-01]\n"," [9.7136658e-01]\n"," [4.8252273e-02]\n"," [6.5578830e-01]\n"," [9.6121669e-01]\n"," [5.3839827e-01]\n"," [9.6980882e-01]\n"," [8.7755191e-01]\n"," [3.7000205e-02]\n"," [7.9559582e-01]\n"," [6.2835366e-03]\n"," [7.9995775e-01]\n"," [8.1930506e-01]\n"," [3.6842334e-01]\n"," [1.5528449e-01]\n"," [9.3721050e-01]\n"," [9.0547121e-01]\n"," [1.6720569e-01]\n"," [5.8272999e-02]\n"," [8.8272065e-01]\n"," [9.8265088e-01]\n"," [6.5790817e-02]\n"," [6.5790817e-02]\n"," [2.0391868e-01]\n"," [1.2757246e-01]\n"," [3.2410061e-01]\n"," [2.1117713e-02]\n"," [2.7402207e-01]\n"," [9.6980882e-01]\n"," [5.5194145e-01]\n"," [8.1777096e-01]\n"," [9.8835540e-01]\n"," [4.7306276e-06]\n"," [9.4143236e-01]\n"," [9.9083382e-01]\n"," [9.9878424e-01]\n"," [1.8960013e-03]\n"," [8.9329350e-01]\n"," [9.7106808e-01]\n"," [9.8563004e-01]\n"," [1.6878208e-02]\n"," [9.2922586e-01]\n"," [8.8429821e-01]\n"," [8.0298775e-01]\n"," [9.6423107e-01]\n"," [9.4499677e-01]\n"," [9.0160167e-01]\n"," [8.9672345e-01]\n"," [9.7882998e-01]\n"," [9.8266727e-01]\n"," [7.4256086e-01]\n"," [9.0906376e-01]\n"," [8.8429821e-01]\n"," [1.1404734e-02]\n"," [1.7027242e-01]\n"," [9.5429981e-01]\n"," [1.5067759e-02]\n"," [9.8480761e-01]\n"," [9.8258227e-01]\n"," [6.3575470e-01]\n"," [8.9512479e-01]\n"," [9.8258227e-01]\n"," [4.7051266e-02]\n"," [5.3440744e-01]\n"," [1.5590812e-01]\n"," [8.2778364e-01]\n"," [9.8858625e-01]\n"," [8.3344334e-01]\n"," [8.7249988e-01]\n"," [8.9512479e-01]\n"," [1.8666247e-01]\n"," [9.9883693e-01]\n"," [7.9795635e-01]\n"," [1.5528449e-01]\n"," [2.2565331e-01]\n"," [8.1905365e-01]\n"," [3.2410061e-01]\n"," [8.1885284e-01]\n"," [2.0234920e-02]\n"," [8.2855505e-01]\n"," [3.7215460e-02]\n"," [6.6560522e-02]\n"," [9.8125803e-01]\n"," [9.1644436e-01]\n"," [8.9043432e-01]\n"," [9.3475020e-01]\n"," [8.6453241e-01]\n"," [4.7459383e-03]\n"," [7.8198785e-01]\n"," [9.0906376e-01]\n"," [6.1848307e-01]\n"," [9.0555489e-01]\n"," [9.3721050e-01]\n"," [3.7000205e-02]\n"," [1.7807992e-02]\n"," [4.6269757e-01]\n"," [2.3581688e-01]\n"," [9.7198808e-01]\n"," [7.6243997e-01]\n"," [6.4027286e-01]\n"," [5.9750432e-01]\n"," [9.9874395e-01]\n"," [2.0764948e-01]\n"," [1.0897921e-02]\n"," [9.4936126e-01]\n"," [7.7327915e-02]\n"," [9.8943669e-01]\n"," [9.2596006e-01]\n"," [1.4602694e-01]\n"," [9.5700139e-01]\n"," [7.5340481e-03]\n"," [6.2718081e-01]\n"," [1.8960013e-03]\n"," [2.0386654e-01]\n"," [9.7881311e-01]\n"," [3.5102531e-02]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(1000, activation='relu', input_dim=13))\n","model.add(Dense(500, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=200)\n","print(model.predict(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUc9KDGJMELx","executionInfo":{"status":"ok","timestamp":1696614391136,"user_tz":-330,"elapsed":84272,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"e1c9e1cd-a454-4210-c458-581782bdaac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 2s 10ms/step - loss: 2.7342 - accuracy: 0.5000\n","Epoch 2/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.7775 - accuracy: 0.6276\n","Epoch 3/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.6524 - accuracy: 0.6562\n","Epoch 4/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.7528 - accuracy: 0.6341\n","Epoch 5/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.6849\n","Epoch 6/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.6042 - accuracy: 0.6732\n","Epoch 7/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.7279\n","Epoch 8/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.5151 - accuracy: 0.7435\n","Epoch 9/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4984 - accuracy: 0.7578\n","Epoch 10/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.5237 - accuracy: 0.7240\n","Epoch 11/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.6137 - accuracy: 0.6914\n","Epoch 12/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.5472 - accuracy: 0.7279\n","Epoch 13/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.7617\n","Epoch 14/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.7852\n","Epoch 15/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4793 - accuracy: 0.7721\n","Epoch 16/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4176 - accuracy: 0.7982\n","Epoch 17/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.7682\n","Epoch 18/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4386 - accuracy: 0.7839\n","Epoch 19/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3883 - accuracy: 0.8255\n","Epoch 20/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4430 - accuracy: 0.7839\n","Epoch 21/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4347 - accuracy: 0.7943\n","Epoch 22/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3822 - accuracy: 0.8320\n","Epoch 23/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.7982\n","Epoch 24/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.8607\n","Epoch 25/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3676 - accuracy: 0.8411\n","Epoch 26/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3588 - accuracy: 0.8464\n","Epoch 27/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3594 - accuracy: 0.8516\n","Epoch 28/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3548 - accuracy: 0.8659\n","Epoch 29/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3752 - accuracy: 0.8333\n","Epoch 30/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3447 - accuracy: 0.8490\n","Epoch 31/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3403 - accuracy: 0.8659\n","Epoch 32/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3504 - accuracy: 0.8490\n","Epoch 33/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3832 - accuracy: 0.8411\n","Epoch 34/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3796 - accuracy: 0.8359\n","Epoch 35/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3388 - accuracy: 0.8633\n","Epoch 36/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3721 - accuracy: 0.8320\n","Epoch 37/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.8451\n","Epoch 38/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8385\n","Epoch 39/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3425 - accuracy: 0.8516\n","Epoch 40/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3746 - accuracy: 0.8424\n","Epoch 41/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3282 - accuracy: 0.8698\n","Epoch 42/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3313 - accuracy: 0.8607\n","Epoch 43/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3308 - accuracy: 0.8607\n","Epoch 44/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.8503\n","Epoch 45/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3242 - accuracy: 0.8607\n","Epoch 46/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3444 - accuracy: 0.8490\n","Epoch 47/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3748 - accuracy: 0.8320\n","Epoch 48/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.8164\n","Epoch 49/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3615 - accuracy: 0.8542\n","Epoch 50/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3468 - accuracy: 0.8464\n","Epoch 51/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3321 - accuracy: 0.8490\n","Epoch 52/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3353 - accuracy: 0.8620\n","Epoch 53/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3404 - accuracy: 0.8555\n","Epoch 54/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3110 - accuracy: 0.8763\n","Epoch 55/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3083 - accuracy: 0.8802\n","Epoch 56/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3182 - accuracy: 0.8594\n","Epoch 57/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4437 - accuracy: 0.7826\n","Epoch 58/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3522 - accuracy: 0.8307\n","Epoch 59/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.8594\n","Epoch 60/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.8542\n","Epoch 61/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3456 - accuracy: 0.8581\n","Epoch 62/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3256 - accuracy: 0.8529\n","Epoch 63/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3676 - accuracy: 0.8268\n","Epoch 64/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.8776\n","Epoch 65/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.8503\n","Epoch 66/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3399 - accuracy: 0.8542\n","Epoch 67/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3110 - accuracy: 0.8659\n","Epoch 68/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3235 - accuracy: 0.8581\n","Epoch 69/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8711\n","Epoch 70/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3223 - accuracy: 0.8698\n","Epoch 71/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.8359\n","Epoch 72/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3126 - accuracy: 0.8646\n","Epoch 73/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3034 - accuracy: 0.8659\n","Epoch 74/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3618 - accuracy: 0.8516\n","Epoch 75/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3355 - accuracy: 0.8620\n","Epoch 76/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3306 - accuracy: 0.8529\n","Epoch 77/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3198 - accuracy: 0.8529\n","Epoch 78/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3092 - accuracy: 0.8646\n","Epoch 79/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3024 - accuracy: 0.8568\n","Epoch 80/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2830 - accuracy: 0.8763\n","Epoch 81/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 0.8724\n","Epoch 82/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3044 - accuracy: 0.8724\n","Epoch 83/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2984 - accuracy: 0.8620\n","Epoch 84/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3168 - accuracy: 0.8555\n","Epoch 85/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.2895 - accuracy: 0.8542\n","Epoch 86/200\n","24/24 [==============================] - 1s 31ms/step - loss: 0.2936 - accuracy: 0.8711\n","Epoch 87/200\n","24/24 [==============================] - 1s 29ms/step - loss: 0.2881 - accuracy: 0.8737\n","Epoch 88/200\n","24/24 [==============================] - 1s 24ms/step - loss: 0.2734 - accuracy: 0.8841\n","Epoch 89/200\n","24/24 [==============================] - 1s 26ms/step - loss: 0.2810 - accuracy: 0.8802\n","Epoch 90/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.2804 - accuracy: 0.8724\n","Epoch 91/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.2708 - accuracy: 0.8802\n","Epoch 92/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2670 - accuracy: 0.8854\n","Epoch 93/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2932 - accuracy: 0.8711\n","Epoch 94/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.2902 - accuracy: 0.8711\n","Epoch 95/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2813 - accuracy: 0.8854\n","Epoch 96/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2656 - accuracy: 0.8880\n","Epoch 97/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3135 - accuracy: 0.8672\n","Epoch 98/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2693 - accuracy: 0.8854\n","Epoch 99/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2835 - accuracy: 0.8802\n","Epoch 100/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2649 - accuracy: 0.8828\n","Epoch 101/200\n","24/24 [==============================] - 0s 21ms/step - loss: 0.2518 - accuracy: 0.8984\n","Epoch 102/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2636 - accuracy: 0.8828\n","Epoch 103/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.2976 - accuracy: 0.8724\n","Epoch 104/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2877 - accuracy: 0.8620\n","Epoch 105/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.2656 - accuracy: 0.8906\n","Epoch 106/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2616 - accuracy: 0.8997\n","Epoch 107/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2973 - accuracy: 0.8659\n","Epoch 108/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2925 - accuracy: 0.8607\n","Epoch 109/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2638 - accuracy: 0.8763\n","Epoch 110/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2394 - accuracy: 0.8945\n","Epoch 111/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.8932\n","Epoch 112/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8620\n","Epoch 113/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2898 - accuracy: 0.8724\n","Epoch 114/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3105 - accuracy: 0.8581\n","Epoch 115/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2778 - accuracy: 0.8672\n","Epoch 116/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2365 - accuracy: 0.8945\n","Epoch 117/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2503 - accuracy: 0.8958\n","Epoch 118/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2468 - accuracy: 0.9036\n","Epoch 119/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2716 - accuracy: 0.8750\n","Epoch 120/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2504 - accuracy: 0.8906\n","Epoch 121/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2207 - accuracy: 0.8997\n","Epoch 122/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2354 - accuracy: 0.8997\n","Epoch 123/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2420 - accuracy: 0.8945\n","Epoch 124/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2361 - accuracy: 0.9010\n","Epoch 125/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.2075 - accuracy: 0.9154\n","Epoch 126/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1936 - accuracy: 0.9102\n","Epoch 127/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2714 - accuracy: 0.8932\n","Epoch 128/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.2237 - accuracy: 0.9102\n","Epoch 129/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2388 - accuracy: 0.8945\n","Epoch 130/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3448 - accuracy: 0.8359\n","Epoch 131/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2544 - accuracy: 0.9010\n","Epoch 132/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2239 - accuracy: 0.9023\n","Epoch 133/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2071 - accuracy: 0.9219\n","Epoch 134/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1961 - accuracy: 0.9115\n","Epoch 135/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2045 - accuracy: 0.9141\n","Epoch 136/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2125 - accuracy: 0.9115\n","Epoch 137/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2169 - accuracy: 0.8945\n","Epoch 138/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2435 - accuracy: 0.8958\n","Epoch 139/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2599 - accuracy: 0.8945\n","Epoch 140/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1946 - accuracy: 0.9180\n","Epoch 141/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2117 - accuracy: 0.9128\n","Epoch 142/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2060 - accuracy: 0.9010\n","Epoch 143/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1821 - accuracy: 0.9219\n","Epoch 144/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2197 - accuracy: 0.9023\n","Epoch 145/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9154\n","Epoch 146/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.1828 - accuracy: 0.9206\n","Epoch 147/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1687 - accuracy: 0.9284\n","Epoch 148/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1745 - accuracy: 0.9245\n","Epoch 149/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1736 - accuracy: 0.9284\n","Epoch 150/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.1518 - accuracy: 0.9388\n","Epoch 151/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1704 - accuracy: 0.9206\n","Epoch 152/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.1900 - accuracy: 0.9297\n","Epoch 153/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.2318 - accuracy: 0.9023\n","Epoch 154/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3455 - accuracy: 0.8633\n","Epoch 155/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3371 - accuracy: 0.8529\n","Epoch 156/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2613 - accuracy: 0.8958\n","Epoch 157/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2464 - accuracy: 0.8906\n","Epoch 158/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2077 - accuracy: 0.9036\n","Epoch 159/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2517 - accuracy: 0.8945\n","Epoch 160/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2176 - accuracy: 0.9010\n","Epoch 161/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.2220 - accuracy: 0.8997\n","Epoch 162/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.9258\n","Epoch 163/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1616 - accuracy: 0.9401\n","Epoch 164/200\n","24/24 [==============================] - 1s 24ms/step - loss: 0.1825 - accuracy: 0.9206\n","Epoch 165/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.2120 - accuracy: 0.9036\n","Epoch 166/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2498 - accuracy: 0.8906\n","Epoch 167/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.1668 - accuracy: 0.9232\n","Epoch 168/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.1770 - accuracy: 0.9141\n","Epoch 169/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3029 - accuracy: 0.8724\n","Epoch 170/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.1960 - accuracy: 0.9141\n","Epoch 171/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.1498 - accuracy: 0.9375\n","Epoch 172/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.1523 - accuracy: 0.9375\n","Epoch 173/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.1432 - accuracy: 0.9466\n","Epoch 174/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.1586 - accuracy: 0.9284\n","Epoch 175/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.1509 - accuracy: 0.9375\n","Epoch 176/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.1300 - accuracy: 0.9479\n","Epoch 177/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.1245 - accuracy: 0.9440\n","Epoch 178/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1273 - accuracy: 0.9479\n","Epoch 179/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.1866 - accuracy: 0.9154\n","Epoch 180/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.1893 - accuracy: 0.9154\n","Epoch 181/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1596 - accuracy: 0.9310\n","Epoch 182/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1389 - accuracy: 0.9401\n","Epoch 183/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1389 - accuracy: 0.9401\n","Epoch 184/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1285 - accuracy: 0.9375\n","Epoch 185/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.1478 - accuracy: 0.9336\n","Epoch 186/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.1333 - accuracy: 0.9414\n","Epoch 187/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.1493 - accuracy: 0.9297\n","Epoch 188/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1741 - accuracy: 0.9245\n","Epoch 189/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.1491 - accuracy: 0.9349\n","Epoch 190/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.1683 - accuracy: 0.9297\n","Epoch 191/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1211 - accuracy: 0.9453\n","Epoch 192/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.0982 - accuracy: 0.9635\n","Epoch 193/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9661\n","Epoch 194/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.1204 - accuracy: 0.9388\n","Epoch 195/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.1675 - accuracy: 0.9349\n","Epoch 196/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.1559 - accuracy: 0.9375\n","Epoch 197/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1793 - accuracy: 0.9180\n","Epoch 198/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.0958 - accuracy: 0.9570\n","Epoch 199/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.0675 - accuracy: 0.9727\n","Epoch 200/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.0767 - accuracy: 0.9714\n","9/9 [==============================] - 0s 6ms/step\n","[[9.9954629e-01]\n"," [9.9999928e-01]\n"," [7.3061765e-06]\n"," [9.9963552e-01]\n"," [3.1526826e-05]\n"," [9.9928111e-01]\n"," [1.5125307e-02]\n"," [1.7587540e-06]\n"," [9.9358904e-01]\n"," [6.2537722e-12]\n"," [9.9969226e-01]\n"," [8.9854339e-06]\n"," [9.9925321e-01]\n"," [1.0000000e+00]\n"," [1.4041096e-07]\n"," [9.0065306e-01]\n"," [2.5269537e-06]\n"," [1.0000000e+00]\n"," [9.9999851e-01]\n"," [3.2260712e-06]\n"," [8.0299056e-01]\n"," [5.6272478e-05]\n"," [5.5470794e-01]\n"," [1.0534680e-08]\n"," [8.0299056e-01]\n"," [9.9999839e-01]\n"," [9.9162447e-01]\n"," [9.9903053e-01]\n"," [9.6593419e-07]\n"," [9.3959838e-01]\n"," [3.1606980e-02]\n"," [9.6983767e-01]\n"," [4.0050733e-01]\n"," [9.9999928e-01]\n"," [9.9959260e-01]\n"," [9.9130678e-01]\n"," [8.0299056e-01]\n"," [7.7721542e-01]\n"," [9.9996918e-01]\n"," [9.9999726e-01]\n"," [1.7587540e-06]\n"," [2.0675845e-06]\n"," [9.8683435e-01]\n"," [5.5470794e-01]\n"," [4.1358234e-13]\n"," [2.8225956e-11]\n"," [9.1954798e-06]\n"," [1.9411647e-03]\n"," [3.3228319e-02]\n"," [2.0482074e-01]\n"," [9.8640990e-01]\n"," [9.1439469e-09]\n"," [3.4302729e-01]\n"," [8.4044262e-13]\n"," [9.9162447e-01]\n"," [9.9996918e-01]\n"," [2.0682335e-05]\n"," [3.5826257e-12]\n"," [1.0976081e-01]\n"," [9.9999863e-01]\n"," [9.4293499e-01]\n"," [9.9614137e-01]\n"," [9.6593237e-07]\n"," [2.0482068e-01]\n"," [5.8746315e-04]\n"," [7.9495803e-05]\n"," [1.0000000e+00]\n"," [1.8596014e-01]\n"," [2.8225956e-11]\n"," [9.9999684e-01]\n"," [1.2919810e-02]\n"," [9.6593419e-07]\n"," [3.9298568e-04]\n"," [9.9962342e-01]\n"," [9.9775922e-01]\n"," [5.0246668e-01]\n"," [1.5125307e-02]\n"," [4.7694743e-03]\n"," [4.2277789e-01]\n"," [9.9506849e-01]\n"," [5.2004814e-04]\n"," [1.2343461e-06]\n"," [3.3691926e-05]\n"," [1.4198388e-06]\n"," [9.9835658e-01]\n"," [1.2351735e-09]\n"," [9.9969226e-01]\n"," [2.2388910e-07]\n"," [5.2004814e-04]\n"," [9.3959838e-01]\n"," [8.9554846e-02]\n"," [3.2260712e-06]\n"," [1.0000000e+00]\n"," [9.9837798e-01]\n"," [9.9907053e-01]\n"," [9.6935320e-01]\n"," [1.8596014e-01]\n"," [1.7243552e-04]\n"," [2.7449340e-13]\n"," [4.5679868e-03]\n"," [1.0000000e+00]\n"," [4.3082950e-01]\n"," [4.6740967e-01]\n"," [9.9825704e-01]\n"," [7.9156460e-05]\n"," [9.9999124e-01]\n"," [3.5826257e-12]\n"," [8.7838483e-01]\n"," [9.8665291e-03]\n"," [9.9989891e-01]\n"," [1.0976081e-01]\n"," [9.9989891e-01]\n"," [1.0000000e+00]\n"," [3.7743119e-04]\n"," [9.9970257e-01]\n"," [9.9999362e-01]\n"," [3.6940560e-01]\n"," [9.9513662e-01]\n"," [9.9782795e-01]\n"," [6.8539193e-06]\n"," [9.9923950e-01]\n"," [9.5454204e-01]\n"," [3.6934686e-08]\n"," [1.5813172e-03]\n"," [9.0425891e-01]\n"," [1.0534680e-08]\n"," [9.9742967e-01]\n"," [9.0560339e-02]\n"," [1.2919810e-02]\n"," [9.9067837e-01]\n"," [9.6983767e-01]\n"," [2.7449340e-13]\n"," [9.9999994e-01]\n"," [1.0000000e+00]\n"," [2.3544690e-05]\n"," [1.0000000e+00]\n"," [2.9213171e-08]\n"," [9.5454204e-01]\n"," [1.0000000e+00]\n"," [3.6940560e-01]\n"," [9.9638242e-01]\n"," [9.8683739e-01]\n"," [9.9987900e-01]\n"," [6.5865988e-01]\n"," [9.8167974e-01]\n"," [9.9574131e-01]\n"," [9.8640990e-01]\n"," [9.9891847e-01]\n"," [3.0257508e-01]\n"," [5.8965870e-06]\n"," [4.0050733e-01]\n"," [2.8225956e-11]\n"," [9.9057359e-01]\n"," [9.9638242e-01]\n"," [5.7584416e-02]\n"," [5.2419360e-05]\n"," [6.7565525e-01]\n"," [9.9067837e-01]\n"," [7.6578546e-04]\n"," [2.0675807e-06]\n"," [9.8683435e-01]\n"," [9.9998039e-01]\n"," [4.3082950e-01]\n"," [4.3082950e-01]\n"," [9.8991197e-01]\n"," [8.5581458e-01]\n"," [1.9128761e-03]\n"," [1.4163489e-03]\n"," [8.7084019e-01]\n"," [9.9891847e-01]\n"," [3.9298568e-04]\n"," [9.6726984e-01]\n"," [9.9999779e-01]\n"," [1.8282947e-27]\n"," [9.6998221e-01]\n"," [9.9999928e-01]\n"," [1.0000000e+00]\n"," [2.5438757e-12]\n"," [4.6740967e-01]\n"," [9.9997306e-01]\n"," [1.0000000e+00]\n"," [3.1127822e-08]\n"," [9.9863148e-01]\n"," [3.4302729e-01]\n"," [9.7990310e-01]\n"," [9.9782795e-01]\n"," [9.9959260e-01]\n"," [1.0976081e-01]\n"," [9.9672997e-01]\n"," [9.9998552e-01]\n"," [9.9988544e-01]\n"," [4.2277789e-01]\n"," [1.9124564e-03]\n"," [3.4302729e-01]\n"," [3.5826257e-12]\n"," [6.3497990e-01]\n"," [8.1180674e-01]\n"," [4.6768116e-07]\n"," [9.9999750e-01]\n"," [9.9999940e-01]\n"," [9.7415262e-01]\n"," [9.9866945e-01]\n"," [9.9999940e-01]\n"," [1.4519851e-09]\n"," [3.9450414e-03]\n"," [3.8562785e-08]\n"," [9.0746307e-01]\n"," [9.2407310e-01]\n"," [8.8773143e-01]\n"," [9.5454204e-01]\n"," [9.9866945e-01]\n"," [2.3878631e-05]\n"," [1.0000000e+00]\n"," [8.9554846e-02]\n"," [5.2419360e-05]\n"," [2.6906838e-04]\n"," [8.1838761e-03]\n"," [1.9128761e-03]\n"," [9.8917913e-01]\n"," [2.3544690e-05]\n"," [9.5742995e-01]\n"," [3.3691926e-05]\n"," [4.5679780e-03]\n"," [9.9999869e-01]\n"," [9.9761188e-01]\n"," [9.7071552e-01]\n"," [9.9513662e-01]\n"," [9.8645478e-01]\n"," [8.9854339e-06]\n"," [9.9923950e-01]\n"," [1.9124564e-03]\n"," [9.6453838e-02]\n"," [3.1685457e-02]\n"," [6.7565525e-01]\n"," [5.8965870e-06]\n"," [1.5125307e-02]\n"," [2.2454199e-03]\n"," [2.0186957e-02]\n"," [9.9986094e-01]\n"," [5.8590886e-03]\n"," [7.9855448e-01]\n"," [1.8597750e-01]\n"," [1.0000000e+00]\n"," [1.6535925e-04]\n"," [4.0572791e-05]\n"," [8.7838483e-01]\n"," [2.3337211e-02]\n"," [1.0000000e+00]\n"," [9.9776185e-01]\n"," [5.6697160e-04]\n"," [9.9962342e-01]\n"," [6.2537722e-12]\n"," [3.1594080e-01]\n"," [2.5438757e-12]\n"," [1.5813156e-03]\n"," [1.0000000e+00]\n"," [1.5429099e-07]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","\n","# Import necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","# Keras specific\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","x=df.drop('target',axis=1)\n","y=df['target']\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n","model = Sequential()\n","model.add(Dense(1000, activation='relu', input_dim=13))\n","model.add(Dense(500, activation='relu'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(x_train,y_train, epochs=200)\n","print(model.predict(x_test))"],"metadata":{"id":"vVIVI5eG7TBP","executionInfo":{"status":"ok","timestamp":1696614474807,"user_tz":-330,"elapsed":83696,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"ac3128c7-d4cc-4318-8537-93a9e81f3e23","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","24/24 [==============================] - 2s 20ms/step - loss: 2.0993 - accuracy: 0.5534\n","Epoch 2/200\n","24/24 [==============================] - 1s 25ms/step - loss: 0.5926 - accuracy: 0.6966\n","Epoch 3/200\n","24/24 [==============================] - 1s 29ms/step - loss: 0.5880 - accuracy: 0.7057\n","Epoch 4/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.8059 - accuracy: 0.6458\n","Epoch 5/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.6479 - accuracy: 0.6458\n","Epoch 6/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.5327 - accuracy: 0.7292\n","Epoch 7/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.6082 - accuracy: 0.7161\n","Epoch 8/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.6992 - accuracy: 0.6706\n","Epoch 9/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7539\n","Epoch 10/200\n","24/24 [==============================] - 1s 23ms/step - loss: 0.4882 - accuracy: 0.7682\n","Epoch 11/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.4553 - accuracy: 0.7839\n","Epoch 12/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.5173 - accuracy: 0.7630\n","Epoch 13/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.4039 - accuracy: 0.8112\n","Epoch 14/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.8385\n","Epoch 15/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.4177 - accuracy: 0.8216\n","Epoch 16/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.4160 - accuracy: 0.8086\n","Epoch 17/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.8060\n","Epoch 18/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.4436 - accuracy: 0.7943\n","Epoch 19/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.4697 - accuracy: 0.7852\n","Epoch 20/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.4050 - accuracy: 0.8190\n","Epoch 21/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3661 - accuracy: 0.8490\n","Epoch 22/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3598 - accuracy: 0.8464\n","Epoch 23/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3813 - accuracy: 0.8372\n","Epoch 24/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.4419 - accuracy: 0.7852\n","Epoch 25/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3653 - accuracy: 0.8411\n","Epoch 26/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.8216\n","Epoch 27/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.4135 - accuracy: 0.8229\n","Epoch 28/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.4327 - accuracy: 0.7930\n","Epoch 29/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.5523 - accuracy: 0.7448\n","Epoch 30/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3919 - accuracy: 0.8320\n","Epoch 31/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3582 - accuracy: 0.8464\n","Epoch 32/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3598 - accuracy: 0.8490\n","Epoch 33/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3577 - accuracy: 0.8529\n","Epoch 34/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3515 - accuracy: 0.8542\n","Epoch 35/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3519 - accuracy: 0.8385\n","Epoch 36/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3380 - accuracy: 0.8633\n","Epoch 37/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.3659 - accuracy: 0.8438\n","Epoch 38/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3542 - accuracy: 0.8451\n","Epoch 39/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3459 - accuracy: 0.8503\n","Epoch 40/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3484 - accuracy: 0.8438\n","Epoch 41/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.3451 - accuracy: 0.8555\n","Epoch 42/200\n","24/24 [==============================] - 1s 24ms/step - loss: 0.3611 - accuracy: 0.8477\n","Epoch 43/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3709 - accuracy: 0.8451\n","Epoch 44/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3366 - accuracy: 0.8737\n","Epoch 45/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3576 - accuracy: 0.8333\n","Epoch 46/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3844 - accuracy: 0.8216\n","Epoch 47/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4117 - accuracy: 0.8151\n","Epoch 48/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.4152 - accuracy: 0.8047\n","Epoch 49/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3391 - accuracy: 0.8607\n","Epoch 50/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3291 - accuracy: 0.8698\n","Epoch 51/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3241 - accuracy: 0.8516\n","Epoch 52/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3182 - accuracy: 0.8581\n","Epoch 53/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3447 - accuracy: 0.8542\n","Epoch 54/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3231 - accuracy: 0.8672\n","Epoch 55/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3178 - accuracy: 0.8724\n","Epoch 56/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3212 - accuracy: 0.8646\n","Epoch 57/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3228 - accuracy: 0.8724\n","Epoch 58/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3371 - accuracy: 0.8568\n","Epoch 59/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3169 - accuracy: 0.8776\n","Epoch 60/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.8581\n","Epoch 61/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3638 - accuracy: 0.8451\n","Epoch 62/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.8620\n","Epoch 63/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3342 - accuracy: 0.8646\n","Epoch 64/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.8685\n","Epoch 65/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3395 - accuracy: 0.8594\n","Epoch 66/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.3755 - accuracy: 0.8268\n","Epoch 67/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3385 - accuracy: 0.8516\n","Epoch 68/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3278 - accuracy: 0.8594\n","Epoch 69/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3611 - accuracy: 0.8529\n","Epoch 70/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3226 - accuracy: 0.8802\n","Epoch 71/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3369 - accuracy: 0.8620\n","Epoch 72/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3238 - accuracy: 0.8581\n","Epoch 73/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3057 - accuracy: 0.8750\n","Epoch 74/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8633\n","Epoch 75/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3289 - accuracy: 0.8529\n","Epoch 76/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3128 - accuracy: 0.8802\n","Epoch 77/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.3267 - accuracy: 0.8555\n","Epoch 78/200\n","24/24 [==============================] - 0s 21ms/step - loss: 0.3528 - accuracy: 0.8490\n","Epoch 79/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3241 - accuracy: 0.8646\n","Epoch 80/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3215 - accuracy: 0.8646\n","Epoch 81/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.3127 - accuracy: 0.8711\n","Epoch 82/200\n","24/24 [==============================] - 0s 19ms/step - loss: 0.2927 - accuracy: 0.8789\n","Epoch 83/200\n","24/24 [==============================] - 1s 21ms/step - loss: 0.2832 - accuracy: 0.8880\n","Epoch 84/200\n","24/24 [==============================] - 0s 20ms/step - loss: 0.2857 - accuracy: 0.8802\n","Epoch 85/200\n","24/24 [==============================] - 1s 22ms/step - loss: 0.3425 - accuracy: 0.8385\n","Epoch 86/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.3223 - accuracy: 0.8659\n","Epoch 87/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.8880\n","Epoch 88/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3064 - accuracy: 0.8698\n","Epoch 89/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2998 - accuracy: 0.8685\n","Epoch 90/200\n","24/24 [==============================] - 0s 18ms/step - loss: 0.2920 - accuracy: 0.8724\n","Epoch 91/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.3195 - accuracy: 0.8594\n","Epoch 92/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 0.8724\n","Epoch 93/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3085 - accuracy: 0.8672\n","Epoch 94/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3098 - accuracy: 0.8516\n","Epoch 95/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3048 - accuracy: 0.8737\n","Epoch 96/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3231 - accuracy: 0.8607\n","Epoch 97/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2867 - accuracy: 0.8750\n","Epoch 98/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2803 - accuracy: 0.8867\n","Epoch 99/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3120 - accuracy: 0.8802\n","Epoch 100/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2957 - accuracy: 0.8789\n","Epoch 101/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2781 - accuracy: 0.8867\n","Epoch 102/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8854\n","Epoch 103/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2798 - accuracy: 0.8763\n","Epoch 104/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2784 - accuracy: 0.8893\n","Epoch 105/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2833 - accuracy: 0.8724\n","Epoch 106/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3044 - accuracy: 0.8698\n","Epoch 107/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2897 - accuracy: 0.8841\n","Epoch 108/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2796 - accuracy: 0.8685\n","Epoch 109/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2727 - accuracy: 0.8841\n","Epoch 110/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2637 - accuracy: 0.8919\n","Epoch 111/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2659 - accuracy: 0.8919\n","Epoch 112/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2580 - accuracy: 0.8893\n","Epoch 113/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3668 - accuracy: 0.8398\n","Epoch 114/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3090 - accuracy: 0.8776\n","Epoch 115/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8815\n","Epoch 116/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3648 - accuracy: 0.8503\n","Epoch 117/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8216\n","Epoch 118/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8581\n","Epoch 119/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.3230 - accuracy: 0.8685\n","Epoch 120/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.3180 - accuracy: 0.8763\n","Epoch 121/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3523 - accuracy: 0.8385\n","Epoch 122/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3251 - accuracy: 0.8607\n","Epoch 123/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 0.8711\n","Epoch 124/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2750 - accuracy: 0.8776\n","Epoch 125/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2740 - accuracy: 0.8893\n","Epoch 126/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2992 - accuracy: 0.8724\n","Epoch 127/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2587 - accuracy: 0.8958\n","Epoch 128/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3118 - accuracy: 0.8607\n","Epoch 129/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2922 - accuracy: 0.8750\n","Epoch 130/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2832 - accuracy: 0.8724\n","Epoch 131/200\n","24/24 [==============================] - 0s 14ms/step - loss: 0.3008 - accuracy: 0.8633\n","Epoch 132/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2831 - accuracy: 0.8854\n","Epoch 133/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2533 - accuracy: 0.8867\n","Epoch 134/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2740 - accuracy: 0.8828\n","Epoch 135/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2701 - accuracy: 0.8893\n","Epoch 136/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.2699 - accuracy: 0.8828\n","Epoch 137/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2915 - accuracy: 0.8763\n","Epoch 138/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2949 - accuracy: 0.8672\n","Epoch 139/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2418 - accuracy: 0.9023\n","Epoch 140/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2482 - accuracy: 0.8971\n","Epoch 141/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2933 - accuracy: 0.8724\n","Epoch 142/200\n","24/24 [==============================] - 0s 9ms/step - loss: 0.2404 - accuracy: 0.8958\n","Epoch 143/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2485 - accuracy: 0.8984\n","Epoch 144/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2472 - accuracy: 0.8919\n","Epoch 145/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2529 - accuracy: 0.8971\n","Epoch 146/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2262 - accuracy: 0.9049\n","Epoch 147/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2243 - accuracy: 0.9128\n","Epoch 148/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2483 - accuracy: 0.9062\n","Epoch 149/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2465 - accuracy: 0.8945\n","Epoch 150/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2191 - accuracy: 0.9141\n","Epoch 151/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2206 - accuracy: 0.9062\n","Epoch 152/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2274 - accuracy: 0.9141\n","Epoch 153/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2785 - accuracy: 0.8711\n","Epoch 154/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2424 - accuracy: 0.8958\n","Epoch 155/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2265 - accuracy: 0.9010\n","Epoch 156/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2231 - accuracy: 0.9062\n","Epoch 157/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2294 - accuracy: 0.9089\n","Epoch 158/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.1967 - accuracy: 0.9180\n","Epoch 159/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9141\n","Epoch 160/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2465 - accuracy: 0.8958\n","Epoch 161/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2821 - accuracy: 0.8737\n","Epoch 162/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.8945\n","Epoch 163/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9232\n","Epoch 164/200\n","24/24 [==============================] - 0s 13ms/step - loss: 0.1831 - accuracy: 0.9206\n","Epoch 165/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1912 - accuracy: 0.9206\n","Epoch 166/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9167\n","Epoch 167/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2044 - accuracy: 0.9049\n","Epoch 168/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1854 - accuracy: 0.9271\n","Epoch 169/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 0.9206\n","Epoch 170/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1877 - accuracy: 0.9206\n","Epoch 171/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.2034 - accuracy: 0.9062\n","Epoch 172/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.1695 - accuracy: 0.9258\n","Epoch 173/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2083 - accuracy: 0.9062\n","Epoch 174/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 0.8867\n","Epoch 175/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2128 - accuracy: 0.9076\n","Epoch 176/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.1846 - accuracy: 0.9154\n","Epoch 177/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2568 - accuracy: 0.8997\n","Epoch 178/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.1960 - accuracy: 0.9128\n","Epoch 179/200\n","24/24 [==============================] - 0s 17ms/step - loss: 0.2057 - accuracy: 0.9076\n","Epoch 180/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.1932 - accuracy: 0.9284\n","Epoch 181/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.2233 - accuracy: 0.9049\n","Epoch 182/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.3411 - accuracy: 0.8607\n","Epoch 183/200\n","24/24 [==============================] - 0s 16ms/step - loss: 0.3294 - accuracy: 0.8646\n","Epoch 184/200\n","24/24 [==============================] - 0s 15ms/step - loss: 0.2192 - accuracy: 0.9115\n","Epoch 185/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1940 - accuracy: 0.9167\n","Epoch 186/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 0.9349\n","Epoch 187/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1471 - accuracy: 0.9466\n","Epoch 188/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1213 - accuracy: 0.9518\n","Epoch 189/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1240 - accuracy: 0.9544\n","Epoch 190/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1295 - accuracy: 0.9492\n","Epoch 191/200\n","24/24 [==============================] - 0s 10ms/step - loss: 0.1206 - accuracy: 0.9518\n","Epoch 192/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1367 - accuracy: 0.9440\n","Epoch 193/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1408 - accuracy: 0.9440\n","Epoch 194/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1641 - accuracy: 0.9310\n","Epoch 195/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1105 - accuracy: 0.9570\n","Epoch 196/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1019 - accuracy: 0.9570\n","Epoch 197/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1029 - accuracy: 0.9609\n","Epoch 198/200\n","24/24 [==============================] - 0s 12ms/step - loss: 0.1485 - accuracy: 0.9297\n","Epoch 199/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.1979 - accuracy: 0.9284\n","Epoch 200/200\n","24/24 [==============================] - 0s 11ms/step - loss: 0.3046 - accuracy: 0.8698\n","9/9 [==============================] - 0s 3ms/step\n","[[9.78003144e-01]\n"," [9.99845505e-01]\n"," [3.12505394e-01]\n"," [9.84360278e-01]\n"," [1.61980819e-02]\n"," [9.96670067e-01]\n"," [5.41841109e-05]\n"," [6.02766592e-03]\n"," [8.86608362e-01]\n"," [4.80065099e-09]\n"," [9.08981919e-01]\n"," [1.32764364e-02]\n"," [9.37769711e-01]\n"," [1.00000000e+00]\n"," [1.34236863e-04]\n"," [9.35987413e-01]\n"," [1.01527397e-03]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [1.69785891e-03]\n"," [4.25000310e-01]\n"," [3.59351523e-02]\n"," [5.58925390e-01]\n"," [1.18659821e-03]\n"," [4.25000310e-01]\n"," [1.00000000e+00]\n"," [9.72193718e-01]\n"," [5.34214675e-01]\n"," [2.15930142e-03]\n"," [7.78534353e-01]\n"," [2.16896296e-01]\n"," [8.32496345e-01]\n"," [5.82305968e-01]\n"," [9.99845505e-01]\n"," [9.96604681e-01]\n"," [9.38974082e-01]\n"," [4.25000310e-01]\n"," [4.50532347e-01]\n"," [9.98279512e-01]\n"," [9.95768726e-01]\n"," [6.02766592e-03]\n"," [2.54623103e-03]\n"," [7.46564507e-01]\n"," [5.58925390e-01]\n"," [1.76298581e-05]\n"," [6.80682497e-05]\n"," [1.17119425e-03]\n"," [7.45431706e-02]\n"," [9.72184181e-01]\n"," [1.59292564e-01]\n"," [4.51171875e-01]\n"," [1.21649576e-03]\n"," [8.70179832e-01]\n"," [8.52611937e-09]\n"," [9.72193718e-01]\n"," [9.98279512e-01]\n"," [1.13968505e-02]\n"," [1.54037534e-05]\n"," [9.87573981e-01]\n"," [9.99991357e-01]\n"," [9.42196012e-01]\n"," [7.56590366e-01]\n"," [2.15929607e-03]\n"," [1.59292594e-01]\n"," [1.63998792e-03]\n"," [8.78658375e-06]\n"," [9.99971688e-01]\n"," [3.12278092e-01]\n"," [6.80682497e-05]\n"," [9.98568535e-01]\n"," [9.34552789e-01]\n"," [2.15930142e-03]\n"," [1.68453436e-03]\n"," [9.44896460e-01]\n"," [9.21985745e-01]\n"," [4.15291071e-01]\n"," [5.41841109e-05]\n"," [3.51539566e-05]\n"," [3.97327900e-01]\n"," [9.25918162e-01]\n"," [7.10080052e-03]\n"," [2.22391958e-04]\n"," [5.76767974e-11]\n"," [1.46813240e-04]\n"," [9.94741023e-01]\n"," [1.50984770e-03]\n"," [9.08981919e-01]\n"," [7.67113990e-04]\n"," [7.10080052e-03]\n"," [7.78534353e-01]\n"," [3.24244022e-01]\n"," [1.69785891e-03]\n"," [1.00000000e+00]\n"," [9.72760916e-01]\n"," [9.47103322e-01]\n"," [9.92823660e-01]\n"," [3.12278092e-01]\n"," [7.61317927e-03]\n"," [1.60289151e-08]\n"," [1.16043537e-07]\n"," [1.00000000e+00]\n"," [5.35667466e-04]\n"," [5.64347863e-01]\n"," [7.84637332e-01]\n"," [1.64336024e-03]\n"," [9.99950945e-01]\n"," [1.54037534e-05]\n"," [9.99402583e-01]\n"," [6.56561553e-02]\n"," [9.92552638e-01]\n"," [9.87573981e-01]\n"," [9.92552638e-01]\n"," [9.99860287e-01]\n"," [2.55440734e-02]\n"," [9.99940217e-01]\n"," [9.96708870e-01]\n"," [9.51982200e-01]\n"," [9.10224199e-01]\n"," [9.99939620e-01]\n"," [4.29751854e-16]\n"," [9.82032716e-01]\n"," [9.24821734e-01]\n"," [3.76386498e-03]\n"," [4.54007745e-01]\n"," [2.88852423e-01]\n"," [1.18659821e-03]\n"," [9.29815412e-01]\n"," [9.02154565e-01]\n"," [9.34552789e-01]\n"," [9.38173294e-01]\n"," [8.32496405e-01]\n"," [1.60289151e-08]\n"," [9.99079704e-01]\n"," [1.00000000e+00]\n"," [6.38722559e-04]\n"," [1.00000000e+00]\n"," [1.15376757e-10]\n"," [9.24821734e-01]\n"," [1.00000000e+00]\n"," [9.51982200e-01]\n"," [9.83187258e-01]\n"," [9.58737969e-01]\n"," [9.95707154e-01]\n"," [1.29611057e-03]\n"," [7.36483693e-01]\n"," [9.98439372e-01]\n"," [4.51171875e-01]\n"," [9.83938515e-01]\n"," [3.45956206e-01]\n"," [1.55498669e-03]\n"," [5.82305968e-01]\n"," [6.80682497e-05]\n"," [6.99829996e-01]\n"," [9.83187258e-01]\n"," [4.54977334e-01]\n"," [1.50093837e-02]\n"," [8.12958181e-01]\n"," [9.38173294e-01]\n"," [8.27699166e-15]\n"," [2.54623219e-03]\n"," [7.46564507e-01]\n"," [9.99979556e-01]\n"," [5.35667466e-04]\n"," [5.35667466e-04]\n"," [1.77864417e-01]\n"," [2.26903290e-01]\n"," [7.88079482e-03]\n"," [1.00742392e-08]\n"," [1.68864075e-02]\n"," [9.83938515e-01]\n"," [1.68453436e-03]\n"," [7.54894674e-01]\n"," [9.99999940e-01]\n"," [7.88833967e-19]\n"," [9.28834856e-01]\n"," [9.99845505e-01]\n"," [1.00000000e+00]\n"," [9.07894137e-05]\n"," [5.64347863e-01]\n"," [9.93260503e-01]\n"," [9.99906421e-01]\n"," [5.82581153e-03]\n"," [9.33708489e-01]\n"," [8.70179832e-01]\n"," [8.35424423e-01]\n"," [9.99939620e-01]\n"," [9.96604681e-01]\n"," [9.87573981e-01]\n"," [9.57154930e-01]\n"," [9.97103870e-01]\n"," [9.80156898e-01]\n"," [3.97327900e-01]\n"," [5.47835171e-01]\n"," [8.70179832e-01]\n"," [1.54037534e-05]\n"," [3.15714985e-01]\n"," [9.02404964e-01]\n"," [9.00050392e-04]\n"," [9.99945581e-01]\n"," [9.98112559e-01]\n"," [3.91542584e-01]\n"," [9.38562930e-01]\n"," [9.98112559e-01]\n"," [1.21711955e-05]\n"," [8.49805400e-02]\n"," [4.28449363e-03]\n"," [1.41892657e-02]\n"," [9.85090792e-01]\n"," [4.72621471e-01]\n"," [9.24821734e-01]\n"," [9.38562930e-01]\n"," [8.32945406e-02]\n"," [1.00000000e+00]\n"," [3.24244022e-01]\n"," [1.50093837e-02]\n"," [2.82567157e-03]\n"," [5.04817069e-01]\n"," [7.88079482e-03]\n"," [7.42306530e-01]\n"," [6.38722559e-04]\n"," [8.03648055e-01]\n"," [5.76767974e-11]\n"," [1.16043537e-07]\n"," [9.99227047e-01]\n"," [8.71336043e-01]\n"," [8.40990901e-01]\n"," [9.10224199e-01]\n"," [9.09321010e-01]\n"," [1.32764364e-02]\n"," [9.82032716e-01]\n"," [5.47835171e-01]\n"," [2.90043175e-01]\n"," [3.68079729e-02]\n"," [8.12958181e-01]\n"," [1.55498669e-03]\n"," [5.41841109e-05]\n"," [3.47608067e-02]\n"," [2.15286277e-02]\n"," [9.79202032e-01]\n"," [5.65689564e-01]\n"," [3.97731274e-01]\n"," [3.07604820e-01]\n"," [1.00000000e+00]\n"," [6.76852167e-02]\n"," [1.84603559e-03]\n"," [9.99402583e-01]\n"," [8.94903508e-07]\n"," [1.00000000e+00]\n"," [9.11599517e-01]\n"," [7.35513400e-03]\n"," [9.44896460e-01]\n"," [4.80065099e-09]\n"," [2.78759878e-02]\n"," [9.07894137e-05]\n"," [4.54007745e-01]\n"," [1.00000000e+00]\n"," [3.16712743e-04]]\n"]}]},{"cell_type":"markdown","source":["#MACHINE LEARNING:\n","\n"],"metadata":{"id":"RqvZGv-cNkMY"}},{"cell_type":"markdown","source":["\n","**DECISION TREE:**\n"],"metadata":{"id":"lmV_kXyUNrQh"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Split the data into features (x) and target labels (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n","\n","# Create and train the Decision Tree Classifier\n","classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy on the test set\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n","\n","# You can also print the classification report for more detailed evaluation\n","report = classification_report(y_test, y_pred)\n","print('Classification Report:\\n', report)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_b9JqNhjNaCv","executionInfo":{"status":"ok","timestamp":1696614474809,"user_tz":-330,"elapsed":198,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"fb165540-0911-4010-d2c7-c1620417da53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        98\n","           1       1.00      1.00      1.00       107\n","\n","    accuracy                           1.00       205\n","   macro avg       1.00      1.00      1.00       205\n","weighted avg       1.00      1.00      1.00       205\n","\n"]}]},{"cell_type":"markdown","source":["**RANDOM FOREST**"],"metadata":{"id":"XDzYeWjEeWtL"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Separate features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a RandomForestRegressor\n","RandomForestRegModel = RandomForestRegressor()\n","RandomForestRegModel.fit(X_train, y_train)\n","\n","# Make regression predictions on the test set\n","y_pred = RandomForestRegModel.predict(X_test)\n","print(y_pred)\n","# Define a threshold for considering a prediction as accurate (you can adjust this threshold)\n","accuracy_threshold = 0.5\n","\n","# Calculate the accuracy based on the threshold\n","accurate_predictions = np.abs(y_pred - y_test) <= accuracy_threshold\n","accuracy = np.mean(accurate_predictions) * 100.0\n","\n","print(f'Accuracy: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"labF2wwJjoqJ","executionInfo":{"status":"ok","timestamp":1696614476354,"user_tz":-330,"elapsed":1710,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"e5614930-79c8-42fc-f3f8-69a87103096c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.99 0.11 0.   1.   0.   0.   0.   0.01 0.   0.   0.03 0.   0.96 0.15\n"," 0.99 0.87 1.   0.01 1.   0.02 1.   0.98 0.91 0.98 0.87 0.99 1.   0.04\n"," 1.   0.86 0.98 0.01 0.   0.95 0.01 0.   0.25 0.   0.87 1.   0.06 1.\n"," 0.99 1.   1.   0.99 0.99 0.05 0.   0.14 0.02 0.   0.96 0.03 0.   0.\n"," 0.   0.9  0.   0.11 0.   0.04 1.   0.05 0.11 0.   0.   0.99 0.89 0.99\n"," 0.9  1.   1.   0.   0.07 0.   0.1  0.81 0.02 0.   0.   0.01 0.98 0.09\n"," 0.98 0.   0.97 0.   1.   0.   0.01 0.   1.   0.94 0.98 0.   0.05 0.\n"," 1.   1.   0.9  0.98 0.98 0.04 0.   0.99 0.   0.85 0.01 0.97 0.95 0.07\n"," 0.99 0.04 0.99 0.   0.89 0.   0.   0.98 0.   0.87 1.   0.   0.02 1.\n"," 0.99 0.96 0.99 0.   0.   0.   1.   1.   0.95 0.08 0.   1.   0.   1.\n"," 0.89 0.02 0.94 0.02 0.25 1.   0.98 0.91 0.91 0.02 0.96 0.91 0.97 0.\n"," 0.06 0.   0.97 0.94 0.   0.   0.   1.   1.   0.01 0.9  0.96 1.   1.\n"," 0.86 1.   1.   0.98 0.97 0.91 0.97 1.   0.13 1.   1.   0.01 0.   0.9\n"," 0.   0.06 0.97 0.01 0.68 0.   0.96 0.   0.04 0.97 0.14 0.99 0.   0.94\n"," 0.68 1.   0.15 0.01 1.   0.99 1.   0.01 0.96]\n","Accuracy: 100.00%\n"]}]},{"cell_type":"markdown","source":["**SVM**"],"metadata":{"id":"CrmQ1vcPi3QU"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create an SVM classifier with a linear kernel\n","classifier = SVC(kernel='linear', random_state=0)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_eC-nghismF","executionInfo":{"status":"ok","timestamp":1696614477758,"user_tz":-330,"elapsed":1424,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"947e959b-7f3f-476f-f783-4b95b48e8ae6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.84\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n","\n","# Create an SVM classifier with a linear kernel\n","classifier = SVC(kernel='linear', random_state=0)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkap8D7v6fEr","executionInfo":{"status":"ok","timestamp":1696614479816,"user_tz":-330,"elapsed":2078,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"7c1970f2-ccff-4060-8233-714a7950118f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.85\n"]}]},{"cell_type":"markdown","source":["**LOGISTIC REGRESSION**"],"metadata":{"id":"PNFO5TVyjzPK"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv('/content/drive/MyDrive/heart.csv.xls')\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n","\n","# Standardize the feature values\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Create a Logistic Regression classifier\n","classifier = LogisticRegression()\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = classifier.predict(X_test)\n","\n","print(y_pred)\n","# Evaluate the model's performance\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weTikZX_60XT","executionInfo":{"status":"ok","timestamp":1696614479817,"user_tz":-330,"elapsed":25,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"bcfacd1d-10c9-4060-9ce2-20307b1fd66c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1\n"," 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0\n"," 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1\n"," 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n"," 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1\n"," 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0\n"," 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0]\n","Accuracy: 0.8521400778210116\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.77      0.84       131\n","           1       0.80      0.94      0.86       126\n","\n","    accuracy                           0.85       257\n","   macro avg       0.86      0.85      0.85       257\n","weighted avg       0.86      0.85      0.85       257\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv('/content/drive/MyDrive/heart.csv.xls')\n","\n","# Select features and target variable\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","# Standardize the feature values\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Create a Logistic Regression classifier\n","classifier = LogisticRegression()\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = classifier.predict(X_test)\n","\n","print(y_pred)\n","# Evaluate the model's performance\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvAM8Vktj8yg","executionInfo":{"status":"ok","timestamp":1696614585387,"user_tz":-330,"elapsed":1804,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"cac1dc9a-00d7-40f2-ed20-d2a26117afe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n"," 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n"," 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n"," 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n"," 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1\n"," 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1]\n","Accuracy: 0.8638132295719845\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.80      0.85       123\n","           1       0.83      0.93      0.88       134\n","\n","    accuracy                           0.86       257\n","   macro avg       0.87      0.86      0.86       257\n","weighted avg       0.87      0.86      0.86       257\n","\n"]}]},{"cell_type":"markdown","source":["**KNN**\n"],"metadata":{"id":"iD69Jlelns92"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecXSWj0-5klz","executionInfo":{"status":"ok","timestamp":1696614600055,"user_tz":-330,"elapsed":480,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"fe3fa775-0793-45c2-88ca-663684285ee3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.75\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zK0A1HxwmrjT","executionInfo":{"status":"ok","timestamp":1696614613329,"user_tz":-330,"elapsed":10,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"182953c6-9cee-4b62-88ee-ad76333a517d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.80\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features (X) and target variable (y)\n","X = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Create a KNN classifier\n","classifier = KNeighborsClassifier(n_neighbors=2, metric='minkowski', p=2)\n","\n","# Fit the classifier on the training data\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsK7R7Vj5p1L","executionInfo":{"status":"ok","timestamp":1696614629125,"user_tz":-330,"elapsed":451,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"06ae2670-0ecb-4824-ff39-dad28858a778"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.95\n"]}]},{"cell_type":"markdown","source":["**NAIVE BAYES**\n"],"metadata":{"id":"5VjvQiPdo1vw"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features (X) and target variable (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n","\n","# Create a Gaussian Naive Bayes classifier\n","model = GaussianNB()\n","\n","# Fit the classifier on the training data\n","model.fit(x_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = model.predict(x_test)\n","\n","print(y_pred)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oD5-tRM2ohG5","executionInfo":{"status":"ok","timestamp":1696614642661,"user_tz":-330,"elapsed":392,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"e770a07f-c6cd-4d94-d804-802215d51f70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1\n"," 1 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1\n"," 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1\n"," 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n"," 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1\n"," 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n"," 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0]\n","Accuracy: 0.7937743190661478\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# Load the heart dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/heart.csv.xls\")\n","\n","# Select features (X) and target variable (y)\n","x = df.drop('target', axis=1)\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=32)\n","\n","# Create a Gaussian Naive Bayes classifier\n","model = GaussianNB()\n","\n","# Fit the classifier on the training data\n","model.fit(x_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = model.predict(x_test)\n","\n","print(y_pred)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDHmnL_D6GIe","executionInfo":{"status":"ok","timestamp":1696614660131,"user_tz":-330,"elapsed":450,"user":{"displayName":"Naipunya P","userId":"03854725837128956336"}},"outputId":"bcaa5cbb-2aee-4b59-8dc9-88633a6da6d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1\n"," 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n"," 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n"," 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n"," 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n"," 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0\n"," 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0]\n","Accuracy: 0.8443579766536965\n"]}]}]}